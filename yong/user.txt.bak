{0}accy Accuracy
{0}adam Adam
{0}adgr AdaGrad
{0}aguw 某一部分
{0}alhh 世界上
{0}alne AlexNet
{0}alpa \alpha
{0}altt Alt
{0}anaa Anaconda
{0}andd Android
{0}andx 巨龙
{0}apii API
{0}argx argmax
{0}arro -->
{0}arrw -->
{0}asci ascii码
{0}assn Assign
{0}augi 花间一拙
{0}aygm 东方不败
{0}banf 隐藏层
{0}barr \bar{}
{0}basc Basic
{0}basi batch_size
{1}bb B
{0}bbdx 子龙
{0}bcgk 取整
{0}bdmw 子龙山人
{0}begn \begin{}
{0}beta \beta
{0}bgjg 也不是
{0}bide 也没有
{0}bpmx BP网络
{0}bppx BP神经网络
{0}bpti BP算法
{0}bwnf 隐含层
{0}calo CapsLock
{1}cc C
{0}cent CentOS
{0}chia China
{0}chii \chi
{0}ciwf 预测值
{0}cjdw 对影成三人
{0}clfa 预加载
{0}clur Cluster
{0}cnne Convolutional$_Neural$_Networks
{0}cnnn CNN
{0}conl Convolutional
{0}conv CONV
{0}coss \cos
{0}cost Cost
{0}cpuu CPU
{0}cqtf 马尔科夫
{0}cree Create
{0}csih 邓林波
{0}ctrl Ctrl
{0}cwwk 鸡公煲
{0}dbov 奇函数
{1}dd D
{0}ddig 万万没想到
{0}ddrq 大的
{0}deep Deep
{0}deft Default
{0}dejf 感受野
{0}dela \Delta
{0}deyw 有谁
{0}dftj 压得
{0}dgcm 三观
{0}dise Discriminative
{0}divv \div
{0}dnww 万人
{0}drot Dropout
{0}drou Dropout
{0}drww 成年人
{0}dtfl 有向无环图
{0}dtkg 感知器模型
{0}dtkk 感知器
{0}dtpu 磁盘空间
{0}dtye dtype
{0}dutg 大半生
{0}dwft 存储过程
{0}dxnt 非线性
{0}dyih 太小
{1}ee E
{0}emas Emacs
{0}emcs Emacs
{0}endd \end{}
{0}esfh 彩超
{1}etaa \eta
{0}fale False
{0}fcla FC$_Layer
{0}fcov 超参数
{0}fcxw 运维
{0}feed feed
{0}fenu 赵鹏飞
{0}feth fetch
{0}fetk 云服务器
{0}ff F
{2}ff 寺
{0}ffaa 零零散散
{1}ffxx f(x)
{1}fgbw 二阶
{0}fhih 越小
{0}fhwg 真命
{0}fhxk 越强
{0}fikk 过滤器
{0}filr filter
{0}fioq 赵小焕
{0}fllg 无力回天
{0}flor floor
{0}fnfx f(x)
{0}fnfxe f(x)$_=$_
{0}fqgk 无事
{0}fqwd 均匀分布
{0}fqxe 元组
{2}ftjg 才是
{0}fttw 运算符
{0}fwod 二分类
{0}fylt 直方图
{0}fyqt 赫高锋
{0}gama \gamma
{0}gcbf 亚马逊云
{0}gcbi 亚马逊
{0}gcmm git$_commit$_-m$_
{1}gcmm git$_commit$_-m
{0}gcyt 不允许
{0}gddh 不存在
{0}gdjr 不太明白
{0}getv get_variable
{0}gfqt 一块儿
{0}gfsv 不需要
{1}gg G
{1}ggbw 一阶
{0}ggwu 一倍
{0}ggxe 一组
{0}giad git$_add
{0}gico git$_commit
{0}gihu GitHub
{0}gipu git$_push
{1}gipu git$_pull
{0}gist git$_status
{0}gitj 还得
{0}gitt Git
{0}giwy 不信
{0}gkbw 整除
{1}gmad 正则项
{0}gmrq 不同的
{0}gmwx 正则化
{0}gngw 曹改玲
{0}gnme Gnome
{0}godx 恶龙
{0}gpcn 一字马
{0}gpsu 与之相关
{0}gpuu GPU
{0}gqgq 玩儿玩儿
{0}gqud 残差
{0}grah Graph
{0}gtng 一般情况下
{0}gutb 正交矩阵
{0}gvgw 曹媛玲
{0}gvrw 开始的时候
{0}gwee 一个月
{0}gwkh 曹合忠
{0}gwww 一个人
{0}gywj 平方公里
{0}hatt \hat{}
{0}hdgd 上古恶龙
{0}heit height
{0}helo Hello
{0}hh 目
{1}hh H
{0}hktk 点积
{0}huqs 上海市普陀区铜川路1781弄真光新村第七小区41栋502
{0}hwtw 占位符
{0}iayt 流式计算
{0}ibwx 池化
{0}idns 没有必要
{0}ihef 派上用场
{1}ii I
{0}iibo 激活函数
{0}iiii 淅淅沥沥
{0}inie initialize
{0}inir initializer
{0}init init
{0}inla Input$_Layer
{0}inpt Input
{0}ipwf 党伟
{0}isre 举杯邀明月
{0}isvb 没想好
{0}iter iter
{0}itud 活着
{0}itwx 泛化
{0}iwnf 池化层
{0}iywy 测试集
{0}jaho ${JAVA_HOME}
{0}jebr JetBrain
{0}jifi 最小二乘法
{1}jj J
{0}jwtc 是什么
{0}keeb keep_prob
{0}kerl Kernel
{0}kfsv 只需要
{0}kgyd 另一方面
{2}khuj 蹭
{0}khwq 跟你
{1}khyc 踱
{1}kk K
{0}kyjg 哑变量
{0}labl label
{0}lama \lambda
{0}layr Layer
{0}lbnf 输出层
{0}lbwf 输出值
{0}lera Learning_Rate
{0}lflf 转置
{0}lfwx 黑化
{0}linx Linux
{0}ljxe 轻量级
{0}lkhk 圆点
{1}ll L
{0}logc Logistic
{1}logc Logistic回归
{0}loss Loss
{0}lptu 连乘
{0}lstm LSTM
{0}ltnf 输入层
{0}ludd 较大
{0}lyng 默认情况下
{1}m 山
{0}mado markdown
{0}manj Manjaro
{0}mean Mean
{0}mgwf 赋值
{0}mgwh 同一个
{1}mm M
{0}mumu \mu
{0}muum \mu
{0}mysl Mysql
{0}nams name_scope
{0}nene Neural$_Networks
{0}netk Network
{0}nkev 劈腿
{0}nlpp NLP
{0}nn 快
{1}nn N
{1}nnsg 乙醇
{0}nqdg 悄然而至
{0}ntih 发小
{0}objt Object
{0}oneh one_hot
{0}onho one_hot
{1}oo O
{0}ooke Zookeeper
{0}open Operation
{0}orac Oracle
{0}orii 数据清洗
{0}orjg 数据量
{0}ormo org-mode
{0}orog 数据类型
{0}orsw 数据可视化
{0}otff 业务需求
{0}ovfi Overfitting
{0}owyt 数值计算
{0}padg padding
{0}pcad 神圣巨龙
{0}phft 视频教程
{0}piip \pi
{0}pkge package
{0}plar placeholder
{0}pola Pooling$_Layer
{0}poog Pooling
{1}pp P
{0}ppro P30$_Pro
{0}prhh 实质上
{0}proo Pro
{0}ptkk 字符串
{0}pufw 补零
{0}purq 之间的
{0}purt 空着手
{0}pvhj 安卓
{0}pwtf 空行
{0}pxfq 神经元
{0}pytn Python
{0}qdql 金三银四
{1}qq Q
{0}qqty 印象笔记
{0}qqwu 多倍
{0}qsfu 独酌无相亲
{0}qvfg 邹博
{0}qyet 鸟用
{1}rasg 的东西
{0}rbfx RBF神经网络
{0}rbov 反函数
{0}redi Redis
{0}regn Regularization
{0}relu RelU
{0}rene ResNet
{0}rese restore
{0}reue reuse
{0}rfmj 的规则
{0}rfrh 挂掉
{0}rgif 牛顿法
{0}rgtw 制表符
{0}rgvt 岳不群
{0}rlwf 返回值
{0}rnug 的情况下
{0}robt Robust
{0}root root
{0}rqpb 的名字
{0}rqtq 的名称
{0}rqwx 持久化
{1}rr R
{0}rtrw 执行操作
{0}rttg 的特征
{0}rtvb 春
{0}rujs 的效果
{0}rwet 的作用
{0}ryaa 的方式
{0}ryjg 的变量
{0}savr Saver
{0}scar scalar
{0}scoe scope
{0}scwf 权值
{0}sdar 核磁共振
{0}serr Server
{0}sesn Session
{1}sgdd SGD
{0}shae shape
{0}shvb 想好
{0}siga \sigma
{0}sigd Sigmod函数
{1}sigd Sigmod
{0}sigf 相当于
{0}sigm sigmoid函数
{1}sigm sigmoid
{0}sinn \sin
{0}snyy 可以认为
{0}sofx Softmax
{1}sofx Softmax回归
{0}solr Solr
{0}soue Source
{0}spwx 可视化
{0}sqrt \sqrt{}
{0}srhh 本质上
{0}srwb 模拟仓
{1}ss S
{0}ssga S型
{0}step Step
{0}stkk 构造器
{0}stom Storm
{0}strs strides
{0}sumy Summary
{0}swsc 榆树
{0}sypo 概率密度函数
{0}sywd 概率分布
{0}syyw 概率论
{0}tahh 选项卡
{0}tanh tanh
{0}tann \tan
{0}task Task
{0}tdax 生成式对抗网络
{0}tdkk 生成器
{0}tdwh 第三个
{0}tenr Tensor
{0}tenw TensorFlow
{0}tfuw 第二部分
{0}tfwh 第二个
{0}tgbg 向下取整
{0}tggo 毛亚亚
{0}tghi 每一步
{0}tguw 第一部分
{0}tgwh 每一个
{0}thbg 向上取整
{0}thea \theta
{0}thee There
{0}thesn (n)
{0}thess (s)
{0}thesv (v)
{0}thet theta
{0}tims \times
{0}tlwh 第四个
{0}tmuq 第几次
{0}tnrq 自己的
{0}tpjq 很容易
{0}tpxp 管综
{0}true True
{1}tt T
{0}ttad 径向基
{0}ttat 特征工程
{0}ttbt 算得了什么
{0}ttwe 怎么使用
{0}tugy 简单来讲
{0}tunn 简书
{0}tvya 复杂度
{0}twgv 笑贫不笑娼
{0}txgg 每一
{0}tyod 很麻烦
{0}ubuu Ubuntu
{0}ucou 交叉熵
{0}udbn 关了
{0}udfj 送进
{0}udtk 卷积
{0}ueqn 前馈
{0}ugaa 交互式
{0}ukkk 判别器
{0}unkn unknown
{0}upxg 首字母
{0}utbl 逆矩阵
{0}utnf 卷积层
{0}utpx 卷积神经网络
{0}utsy 卷积核
{0}uttj 疼得
{1}uu U
{0}uwtb 单位矩阵
{0}vale Value
{0}vare Variable
{0}vars variable_scope
{0}vecc \vec{}
{0}vgne VGGNet
{0}vikm 女演员
{0}vimm Vim
{0}vmwe Vmware
{0}vmwo Vmware$_Workstation
{0}vv 女
{1}vv V
{0}vwqt 媳份儿
{0}wbov 值函数
{0}wdaa 分布式
{0}wdat 分布式计算
{0}wdbl 代克孟
{0}wdbn 做了
{0}wdgi 从大到小
{0}wdsg 优酷
{0}wefa 作用域
{0}weio weidongcao
{1}wggf 依赖于
{0}wggo 停下来
{0}wgnt 依赖性
{0}wgtf 全选
{0}widh width
{0}wiha \widehat{}
{0}winds Windows
{0}wins Windows
{0}wlrn 全连接层
{0}wlru 全连接
{0}wmab 华山医院
{0}wnov 偏导数
{0}wokk 分类器
{0}word World
{0}wqjg 你是
{0}wqpu 命名空间
{0}wqrq 您的
{0}wttf 任我行
{1}ww W
{1}wwgi 俭
{0}wwkk 优化器
{1}wwrq 人的
{0}wxyl 华为
{0}wydh 停在
{0}wyih 偏小
{0}wylf 偏置
{1}wynf 偏导
{0}wypy 人为定义
{0}xgbt XGBoost
{0}xiix \xi
{0}xwft 纳什均衡
{1}xx X
{0}xxlm X轴
{0}xxyy (x,y)
{0}yaud 试着
{0}yawd 高斯分布
{0}yfjg 方老师
{0}ygqt 这事儿
{0}ygwx 序列化
{0}ygyq 语义
{0}yhrh 这些年
{0}yiwt 这没什么
{0}yjqt 变量名称
{0}yjwf 变量作用域
{0}ymcd 调参
{0}ymwd 调优
{0}ynud 望着
{0}ysqk 主机名
{0}ysyi 这样就
{0}ywhv 文件目录
{0}ywqk 文件名
{1}yy Y
{0}yylm Y轴
{0}yyrh 试试看
{0}yyrk 试试看吧
